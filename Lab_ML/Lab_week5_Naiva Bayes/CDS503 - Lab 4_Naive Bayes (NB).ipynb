{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QQ-hXOSZ1xj"
   },
   "source": [
    "# CDS503: Machine Learning\n",
    "\n",
    "***\n",
    "## LAB 4: Naive Bayes (NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kOGShBPeZ1xn"
   },
   "source": [
    "In this lab, we will be taking a *closer* look at **naive Bayes classification**.\n",
    "\n",
    "Naive Bayes models are a group of extremely fast and simple classification algorithms that are often suitable for very high-dimensional datasets. Because they are so fast and have so few tunable parameters, they end up being very useful as a *quick-and-dirty* **baseline** for a classification problem. This lab will focus on an *intuitive* explanation of how naive Bayes classifiers **work**, followed by a couple examples of them in action on some datasets.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Step1: Business Understanding\n",
    "\n",
    "***\n",
    "\n",
    "This data was extracted from the census bureau database found at: http://www.census.gov/ftp/pub/DES/www/welcome.html. It contains the cencus income of the people. They are trying to see the income of more than 50k and less than 50k.\n",
    "| Probability for the label '>50K'  : 23.93% / 24.78% (without unknowns)\n",
    "| Probability for the label '<=50K' : 76.07% / 75.22% (without unknowns)\n",
    "\n",
    "<img src=\"Part 1.png\" style=\"width:80%;margin-left:auto;margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2jNBJReHZ1xq"
   },
   "source": [
    "***\n",
    "### Bayesian Classification\n",
    "\n",
    "Naive Bayes classifiers are built on Bayesian classification methods.\n",
    "These rely on **Bayes's theorem**, which is an equation describing the *relationship* of **conditional probabilities** of statistical quantities.\n",
    "In Bayesian classification, we're interested in finding the **probability** of a label *given* some **observed** features, which we can write as $P(L~|~{\\rm features})$.\n",
    "Bayes's theorem tells us how to express this in terms of quantities we can compute more directly:\n",
    "\n",
    "$$\n",
    "P(L~|~{\\rm features}) = \\frac{P({\\rm features}~|~L)P(L)}{P({\\rm features})}\n",
    "$$\n",
    "\n",
    "If we are trying to decide between two labels—let's call them $L_1$ and $L_2$—then one way to make this decision is to compute the ratio of the posterior probabilities for each label:\n",
    "\n",
    "$$\n",
    "\\frac{P(L_1~|~{\\rm features})}{P(L_2~|~{\\rm features})} = \\frac{P({\\rm features}~|~L_1)}{P({\\rm features}~|~L_2)}\\frac{P(L_1)}{P(L_2)}\n",
    "$$\n",
    "\n",
    "All we need now is some model by which we can compute $P({\\rm features}~|~L_i)$ for each label.\n",
    "Such a model is called a *generative model* because it specifies the hypothetical random process that generates the data.\n",
    "Specifying this generative model for each label is the main piece of the training of such a Bayesian classifier.\n",
    "The general version of such a training step is a very difficult task, but we can make it simpler through the use of some simplifying assumptions about the form of this model.\n",
    "\n",
    "**What does it mean?** For example, it means we have to assume that the comfort of the room on the Titanic is *independent* of the fare ticket. This **assumption** is absolutely *wrong* and it is why it is called **Naive**. It allows to simplify the calculation, even on very large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rqrE3H1PZ1yq"
   },
   "source": [
    "***\n",
    "### Different distribution function\n",
    "\n",
    "To begin to implement a classifier, there is a few probability model *options* in the `sklearn` python library. They are:\n",
    "\n",
    "-  **Gaussian**: It *assumes* that **continuous features** follow a normal distribution.\n",
    "\n",
    "<img src=\"02a.png\" style=\"width:70%;margin-left:auto;margin-right:auto;\">\n",
    "\n",
    "-  **Multinomial**: It is useful if your **features are discrete**.\n",
    "-  **Bernoulli**: The binomial model is useful if your **features are binary**.\n",
    "\n",
    "<img src=\"02b.png\" style=\"width:70%;margin-left:auto;margin-right:auto;\">\n",
    "\n",
    "- **Bernoulli Naive Bayes** : It assumes that all our features are binary such that they take only two values. Means 0s can represent “word does not occur in the document” and 1s as \"word occurs in the document\" .\n",
    "\n",
    "- **Multinomial Naive Bayes** : Its is used when we have discrete data (e.g. movie ratings ranging 1 and 5 as each rating will have certain frequency to represent). In text learning we have the count of each word to predict the class or label.\n",
    "\n",
    "- **Gaussian Naive Bayes** : Because of the assumption of the normal distribution, Gaussian Naive Bayes is used in cases when all our features are continuous. For example in Iris dataset features are sepal width, petal width, sepal length, petal length. So its features can have different values in data set as width and length can vary. We can’t represent features in terms of their occurrences. This means data is continuous. Hence we use Gaussian Naive Bayes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Different** types of naive Bayes classifiers rest on **different naive assumptions** about the data, and we will examine a few of these in the following sections. Here we implement a classic **Gaussian Naive Bayes** on the **Titanic Disaster** dataset. We begin with the *standard library imports*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Part 2.png\" style=\"width:80%;margin-left:auto;margin-right:auto;\">\n",
    "\n",
    "### Step 2: Data Understanding\n",
    "\n",
    "#### Description of the data:\n",
    "In the censuc income data set, there are fifteen attributes including the class attribute indicating the class/category information. \n",
    "The 15 attributes are:\n",
    "-  age: continuous.\n",
    "-  workclass:\n",
    "    - Private\n",
    "    - Self-emp-not-inc\n",
    "    - Self-emp-inc\n",
    "    - Federal-gov\n",
    "    - Local-gov\n",
    "    - State-gov\n",
    "    - Without-pay\n",
    "    - Never-worked\n",
    "- fnlwgt: continuous.\n",
    "- education: \n",
    "    - Bachelors \n",
    "    - Some-college\n",
    "    - 11th\n",
    "    - HS-grad\n",
    "    - Prof-school\n",
    "    - Assoc-acdm\n",
    "    - Assoc-voc\n",
    "    - 9th\n",
    "    - 7th-8th\n",
    "    - 12th\n",
    "    - Masters\n",
    "    - 1st-4th\n",
    "    - 10th\n",
    "    - Doctorate\n",
    "    - 5th-6th\n",
    "    - Preschool\n",
    "- education-num: continuous.\n",
    "- marital-status: \n",
    "    - Married-civ-spouse\n",
    "    - Divorced\n",
    "    - Never-married\n",
    "    - Separated\n",
    "    - Widowed\n",
    "    - Married-spouse-absent\n",
    "    - Married-AF-spouse\n",
    "- occupation: \n",
    "    - Tech-support\n",
    "    - Craft-repair\n",
    "    - Other-service\n",
    "    - Sales\n",
    "    - Exec-managerial\n",
    "    - Prof-specialty\n",
    "    - Handlers-cleaners\n",
    "    - Machine-op-inspct\n",
    "    - Adm-clerical\n",
    "    - Farming-fishing\n",
    "    - Transport-moving\n",
    "    - Priv-house-serv\n",
    "    - Protective-serv\n",
    "    - Armed-Forces\n",
    "- relationship: \n",
    "    - Wife\n",
    "    - Own-child\n",
    "    - Husband\n",
    "    - Not-in-family\n",
    "    - Other-relative\n",
    "    - Unmarried\n",
    "- race: \n",
    "    - White\n",
    "    - Asian-Pac-Islander\n",
    "    - Amer-Indian-Eskimo\n",
    "    - Other\n",
    "    - Black\n",
    "- sex: \n",
    "    - Female\n",
    "    - Male\n",
    "- capital-gain: continuous\n",
    "- capital-loss: continuous\n",
    "- hours-per-week: continuous.\n",
    "- native-country: \n",
    "    - United-States\n",
    "    - Cambodia\n",
    "    - England\n",
    "    - Puerto-Rico\n",
    "    - Canada\n",
    "    - Germany\n",
    "    - Outlying-US(Guam-USVI-etc)\n",
    "    - India\n",
    "    - Japan\n",
    "    - Greece\n",
    "    - South\n",
    "    - China\n",
    "    - Cuba\n",
    "    - Iran\n",
    "    - Honduras\n",
    "    - Philippines\n",
    "    - Italy\n",
    "    - Poland\n",
    "    - Jamaica\n",
    "    - Vietnam\n",
    "    - Mexico\n",
    "    - Portugal\n",
    "    - Ireland\n",
    "    - France\n",
    "    - Dominican-Republic\n",
    "    - Laos\n",
    "    - Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador,    Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2491</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>2727</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>13188</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>14354</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18120</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0   22          5    2491          9             12               4   \n",
       "1   33          4    2727          9             12               2   \n",
       "2   21          2   13188         11              8               0   \n",
       "3   36          2   14354          1              6               2   \n",
       "4   11          2   18120          9             12               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0           0             1     4    1            24             0   \n",
       "1           3             0     4    1             0             0   \n",
       "2           5             1     4    1             0             0   \n",
       "3           5             0     2    1             0             0   \n",
       "4           9             5     2    0             0             0   \n",
       "\n",
       "   hours-per-week  native-country  Class  \n",
       "0              39              38      0  \n",
       "1              12              38      0  \n",
       "2              39              38      0  \n",
       "3              39              38      0  \n",
       "4              39               4      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.435482</td>\n",
       "      <td>2.199324</td>\n",
       "      <td>9825.221504</td>\n",
       "      <td>10.333764</td>\n",
       "      <td>9.121312</td>\n",
       "      <td>2.580134</td>\n",
       "      <td>5.959850</td>\n",
       "      <td>1.418341</td>\n",
       "      <td>3.678602</td>\n",
       "      <td>0.675685</td>\n",
       "      <td>6.552450</td>\n",
       "      <td>2.072641</td>\n",
       "      <td>39.871527</td>\n",
       "      <td>36.382567</td>\n",
       "      <td>0.248922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.125355</td>\n",
       "      <td>0.953925</td>\n",
       "      <td>5671.017927</td>\n",
       "      <td>3.812292</td>\n",
       "      <td>2.549995</td>\n",
       "      <td>1.498016</td>\n",
       "      <td>4.029566</td>\n",
       "      <td>1.601338</td>\n",
       "      <td>0.834709</td>\n",
       "      <td>0.468126</td>\n",
       "      <td>23.284819</td>\n",
       "      <td>10.028470</td>\n",
       "      <td>11.771826</td>\n",
       "      <td>6.105372</td>\n",
       "      <td>0.432396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5025.250000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9689.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14520.750000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20262.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age     workclass        fnlwgt     education  education-num  \\\n",
       "count  30162.000000  30162.000000  30162.000000  30162.000000   30162.000000   \n",
       "mean      21.435482      2.199324   9825.221504     10.333764       9.121312   \n",
       "std       13.125355      0.953925   5671.017927      3.812292       2.549995   \n",
       "min        0.000000      0.000000      0.000000      0.000000       0.000000   \n",
       "25%       11.000000      2.000000   5025.250000      9.000000       8.000000   \n",
       "50%       20.000000      2.000000   9689.500000     11.000000       9.000000   \n",
       "75%       30.000000      2.000000  14520.750000     12.000000      12.000000   \n",
       "max       71.000000      6.000000  20262.000000     15.000000      15.000000   \n",
       "\n",
       "       marital-status    occupation  relationship          race           sex  \\\n",
       "count    30162.000000  30162.000000  30162.000000  30162.000000  30162.000000   \n",
       "mean         2.580134      5.959850      1.418341      3.678602      0.675685   \n",
       "std          1.498016      4.029566      1.601338      0.834709      0.468126   \n",
       "min          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%          2.000000      2.000000      0.000000      4.000000      0.000000   \n",
       "50%          2.000000      6.000000      1.000000      4.000000      1.000000   \n",
       "75%          4.000000      9.000000      3.000000      4.000000      1.000000   \n",
       "max          6.000000     13.000000      5.000000      4.000000      1.000000   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "count  30162.000000  30162.000000    30162.000000    30162.000000   \n",
       "mean       6.552450      2.072641       39.871527       36.382567   \n",
       "std       23.284819     10.028470       11.771826        6.105372   \n",
       "min        0.000000      0.000000        0.000000        0.000000   \n",
       "25%        0.000000      0.000000       39.000000       38.000000   \n",
       "50%        0.000000      0.000000       39.000000       38.000000   \n",
       "75%        0.000000      0.000000       44.000000       38.000000   \n",
       "max      117.000000     89.000000       93.000000       40.000000   \n",
       "\n",
       "              Class  \n",
       "count  30162.000000  \n",
       "mean       0.248922  \n",
       "std        0.432396  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30162, 15)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library to display multiple outputs\n",
    "from IPython.display import display\n",
    "\n",
    "# Importing dataset\n",
    "train = pd.read_csv(\"input/adult_train_modified.csv\")\n",
    "test = pd.read_csv(\"input/adult_test_modified.csv\")\n",
    "\n",
    "# see some of it, their overall statistics and dimensions\n",
    "display(train.head(5))\n",
    "display(train.describe())\n",
    "display(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Step 3: Data Preparation\n",
    "\n",
    "We will clea our data by replace some missing values and encoding.\n",
    "\n",
    "<img src=\"Part 3.png\" style=\"width:80%;margin-left:auto;margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new sample after cleaning\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new sample after cleaning\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
      "0       22          5    2491          9             12               4   \n",
      "1       33          4    2727          9             12               2   \n",
      "2       21          2   13188         11              8               0   \n",
      "3       36          2   14354          1              6               2   \n",
      "4       11          2   18120          9             12               2   \n",
      "...    ...        ...     ...        ...            ...             ...   \n",
      "30157   10          2   15471          7             11               2   \n",
      "30158   23          2    7555         11              8               2   \n",
      "30159   41          2    7377         11              8               6   \n",
      "30160    5          2   12060         11              8               4   \n",
      "30161   35          3   16689         11              8               2   \n",
      "\n",
      "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
      "0               0             1     4    1            24             0   \n",
      "1               3             0     4    1             0             0   \n",
      "2               5             1     4    1             0             0   \n",
      "3               5             0     2    1             0             0   \n",
      "4               9             5     2    0             0             0   \n",
      "...           ...           ...   ...  ...           ...           ...   \n",
      "30157          12             5     4    0             0             0   \n",
      "30158           6             0     4    1             0             0   \n",
      "30159           0             4     4    0             0             0   \n",
      "30160           0             3     4    1             0             0   \n",
      "30161           3             5     4    0           107             0   \n",
      "\n",
      "       hours-per-week  native-country  \n",
      "0                  39              38  \n",
      "1                  12              38  \n",
      "2                  39              38  \n",
      "3                  39              38  \n",
      "4                  39               4  \n",
      "...               ...             ...  \n",
      "30157              37              38  \n",
      "30158              39              38  \n",
      "30159              39              38  \n",
      "30160              19              38  \n",
      "30161              39              38  \n",
      "\n",
      "[30162 rows x 14 columns]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "30157    0\n",
      "30158    1\n",
      "30159    0\n",
      "30160    0\n",
      "30161    1\n",
      "Name: Class, Length: 30162, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Assign input column and label column for train data\n",
    "x_train = train.iloc[:,:-1]\n",
    "y_train = train.iloc[:,14]\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
      "0        8          2    8315          1              6               4   \n",
      "1       21          2    1754         11              8               2   \n",
      "2       11          1   10750          7             11               2   \n",
      "3       27          2    4780         15              9               2   \n",
      "4       17          2    7091          0              5               4   \n",
      "...    ...        ...     ...        ...            ...             ...   \n",
      "15055   16          2    8927          9             12               4   \n",
      "15056   22          2    7893          9             12               0   \n",
      "15057   21          2   11193          9             12               2   \n",
      "15058   27          2    1593          9             12               0   \n",
      "15059   18          3    6062          9             12               2   \n",
      "\n",
      "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
      "0               6             3     2    1             0             0   \n",
      "1               4             0     4    1             0             0   \n",
      "2              10             0     4    1             0             0   \n",
      "3               6             0     2    1            87             0   \n",
      "4               7             1     4    1             0             0   \n",
      "...           ...           ...   ...  ...           ...           ...   \n",
      "15055           9             3     4    1             0             0   \n",
      "15056           9             1     4    0             0             0   \n",
      "15057           9             0     4    1             0             0   \n",
      "15058           0             3     1    1            73             0   \n",
      "15059           3             0     4    1             0             0   \n",
      "\n",
      "       hours-per-week  native-country  \n",
      "0                  39              37  \n",
      "1                  49              37  \n",
      "2                  39              37  \n",
      "3                  39              37  \n",
      "4                  29              37  \n",
      "...               ...             ...  \n",
      "15055              39              37  \n",
      "15056              35              37  \n",
      "15057              49              37  \n",
      "15058              39              37  \n",
      "15059              59              37  \n",
      "\n",
      "[15060 rows x 14 columns]\n",
      "0        0\n",
      "1        0\n",
      "2        1\n",
      "3        1\n",
      "4        0\n",
      "        ..\n",
      "15055    0\n",
      "15056    0\n",
      "15057    0\n",
      "15058    0\n",
      "15059    1\n",
      "Name: Class, Length: 15060, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Assign input column and label column for test data\n",
    "x_test = test.iloc[:,:-1]\n",
    "y_test = test.iloc[:,14]\n",
    "\n",
    "print(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's **clean** the data by *removing* the NaN data **completely**, and *replace* **categorical** values into **numeric** values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Step 4: Modelling\n",
    "#### Classify using Naive Bayes\n",
    "\n",
    "\n",
    "Here, weparate the *descriptive* features and the *target* feature (`Income`) of the data. We assign the **training** set and **testing** set. After the label encoding, the income now becomes (`0 for Income <=50k`) and (`1 for income >50k`).\n",
    "\n",
    "<img src=\"Part 4.png\" style=\"width:80%;margin-left:auto;margin-right:auto;\">\n",
    "\n",
    "### Step 5: Evaluation\n",
    "\n",
    "<img src=\"Part 5.png\" style=\"width:80%;margin-left:auto;margin-right:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train the **Gaussian Naive Bayes** classifier and test it to see its *performance* in term of **accuracy**. From there, we can observe the misclassified ones using the *confusion matrix*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 15060 points : 2800, performance 81.41%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 24.0, 'Predicted label')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAFNCAYAAAAEmbVjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyF0lEQVR4nO3dd5wV1f3/8dfbRaUozRZEbFGjYosVC8beosEebKDRL7HFRJP4U2OiMTExRY0mlhCNgjVYsWE0RiyJCIpYUFQsoWMBRMAG+/n9MWd1vOwuuyuz5d7308c8duZMOWeGXe/nfs6ZGUUEZmZmZuVsmZZugJmZmVnRHPCYmZlZ2XPAY2ZmZmXPAY+ZmZmVPQc8ZmZmVvYc8JiZmVnZc8BjS42kcyRd09LtMDMzK+WAxz4n6W1JMyV1ypWdIGlkQ/aPiN9ExAkFtGukpI8lzZP0gaTHJW26tOv5qiStI6la0pUt3ZaiSPqBpLckzZX0jKSdcusOl/RfSQsa+juT9rtOUkhaL1e2vKS/p3pmSDojt65v+l3ITyHpkLT+6pJ1n0j6MLd/d0l3SZov6X+Sjsyt6yPpYUmzJL0r6TZJPXLrz5f0Wcnx103rVpV0i6Rp6ff0P5K2y+27q6QXJc2R9H5qQ8/c+j9Kel3Sh5ImSBpQx/UamM73hJLy09O1+iBdu+Vz626UND1dz9fy+0o6quR8FqTjb9XQf0OztsABj5VqB/ywpRtRi1MjYgVgJWAkcEPLNqdWA4DZQP/8h01zkFTVDHVsB1wEHAp0Aa4F7srVPQv4U9qmocfcCfh6LavOB9YH1gJ2Bc6UtA9ARDwRESvUTMD+wDzgwbT+xJL1twC35Y59BfApsBpwFHCVpN5pXTdgMLB2qvtD4LqStv0jf/yIeDOVrwCMAbYCugNDgPslrZDWvwzsHRFdgdWB14GrcsedDxxAdm0HApdJ2qHkenUDzgbGl5TvDZwF7J7avi7wy9wmvwXWjojOwHeAX9cENBFxU8n1Ohl4ExiLWRlxwGOl/gD8RFLX2lZKukzS5PRN8VlJfXPrzpd0Y5p/UNKpJfs+L+ngNL9h7pv0q5IOb0jjImIhcCuwce6420p6Kn1zni7pL5KWS+uukHRxSTvulfSjNL+6pDvSt/m3JJ1Wctxn0rnOlHTJEpo3ADgX+IzsgytfZz9J49Kx3qj58E7ZhutSVmC2pLtT+bGSniw5xudZEEnXS7pK0gOS5gO7Svq2pOdSHZMlnV+y/07KMjBz0vpjJW2Tzq1dbrtDJI2r5fzWBsZHxLORPaJ9KLAysCpARPwrIoYB05ZwnWrqaQf8GTi1ltUDgF9FxOyIeAX4G3BsHYcaCNweEfNrqaMTcAhZ8JFf/nlEzIuIJ4F7gGPSOYyIiNsiYm5ELAD+AuzYkPOJiDcj4pKImB4RiyJiMLAc8I20fmZE5K/NImC93P7nRcSEiKiOiKeBJ4DtS6r5LXA58F4t1+DaiBgfEbOBX5G7Xqn8k5rFNNUWaNYca2j4MfxWZhzwWKlnyDIoP6lj/RhgC7JvsDcDt0lqX8t2NwNH1CxI2pjsG/P96UPn4bTNqmm7K3PfsuuUApmjgFG54kXA6WQfvtuTfcs9Oa0bAhwhaZm0/8pp/S2p7F7geaBnKv9R+rYMcBlwWfpW/HVgWD3t6gusQRaMDSP7wK5Zty1ZcPBToCuwM/B2Wn0D0BHona7FpUu6BjlHAhcCKwJPkmUIBqQ6vg2cJOnA1IY1gRFkAcYqZP+G4yJiDPA+sGfuuEcDN0haMwVHa6byEUCVpO1SVud7wDhgRiPanHc68HhEvJAvTFmM1cn+XWo8T3aNKNm2I1nGaUgddRwCvAs8npY3ABZFxGtLOnayMyXZFOCAFKiPl3RSHfshaQuygGdirmxNSXOAj8j+xn5fx74dgG3ydaffo62Bq2vZpTeLX6/VJK2U2/9KSQuACcB04IFa6l2L7JyH1nVeZm1WRHjyRERA9iG8B7AJ8AHZB+MJwMh69pkNbJ7mzwduTPMrkn0Ar5WWLwT+nua/CzxRcpy/AufVUcdIYAEwh6wr4gNg93ra9CPgrtzyK8Ceaf5U4IE0vx0wqWTfs4Hr0vzjZN0CKzfg2l0D3J3mtyfL8qyaO7dLa9mnB1ANdKtl3bHAkyVlAayX5q8n+xZeX5v+VFNvOq+76tju/wE3pfnu6Vr3qGU7Aeekc1tIlmXYppbt6v2dSdv0IgsEutRybr3Scvvc9nsCb9dynGOAtwDVUc8jwPm55b7AjJJt/q+29gKbkXXT9c2VbUwWjFUBO5AFDkfUsm9n4EXg7Dra1T1d9z51rB9C1kWntFxF9mVk+9zfxAm57d8A9sktL5uu4dolx60CdiLLRC5bS70/X9K/nSdPbXVyhscWExEvAfeRjQn4Ekk/lvSKsoGRc8jGG6xcyzE+BO4H+qei/sBNaX4tYLuUPZiTjnMU8LV6mnVaZGMf2pON2bhd0mapTRtIuk/ZgM25wG9K2jSELGtB+lkz/mctYPWSdpxDNrYD4HiyjMAESWMk7V9bw9K38cNqzi8ingImkWVgIPsAf6OWXXsBsyLrgmiKySXt2E7So6l77gPgRL64DnW1AeBGsqzFCsDhZMHo9Fq2O4Esq9ObLHNxNHCfpNWb0PY/ARdExAe1rJuXfnbOlXUmG09Tqs7uF0m9gG/x5WzFvJLj1nrs1HU4AvhhRDxRUx4RL0fEtMi6rP5LlgU8tGTfDmSZw1ER8dta2kxEzCL7vRye705M+/+B7EvH4bnzOhl4If1u1ab0vGrmv3Reqd1PkmUja8tODaDubJlZm+aAx+pyHtk33/xdJH3JvpUeTpaV6EqWbVEdx7iFrDtpe6AD8Ggqnww8FhFdc9MKEVFn90CNyMY3PEGWHdgrFV9FlqZfP7Lup3NK2nQj0E/S5sBGwN25drxV0o4VI2K/VNfrEXEEWVfT78iCrE4s7iCyD5grU9A1I123Abl6ahsvMRnortrHS80n6+oCQFJtwWDph/zNZONRekVEF7Kuj5rrUFcbiIipwFPpPI6h7gHhmwP3RsRr6d/hQbIMxw51bF+f3YE/5K4XwFOSjkwB4PRUX77u0oG6vYBdqLv7ZQDw3/hiUDHAa0A7SevXdezUrfMvsjFESxocH+R+15QNVr8bmAp8fwn7tiP73fo8UJH0S2BfYK+ImJvbdnfgoNz12gG4WNJf0vrxLH69ZkbE+/XU/aXfB0k7kmWvbl9Cu83appZOMXlqPROpSyu3/Dey8R0j0/J+ZANSv0b2Df8XZONn9kjrzyd1aaXl5cm6vB4m16VD1t31P7IP12XTtA2wUR3tGsmX0/fbkwUE+6bl0aktAjYEXmXx7qCHgRdI3WqprAp4liyI65CWNyF105BlMFZJ83sAH5PrZskd559kdyx9LTdtRdZdtSmwLVl33O5kXzJ6Ahumfe8nC1S6peuwcyrfAPiEbKxNe7LgpbRL69cl7XgHGJjmt03LNV2Ma5J92z+c7MNuJWCL3L5HkXXBzAU61fHvMJAsYFg3Xes9ybq/Nsxdz/ZkmaXH0/xi3SZp21VLrlcAfYAOaf1FwGPpumxIFgDtU3KMc8jGANX1+/wq8L1aym8lC8Y7kQ1I/gDondb1JMuE/bSOY/ZLbVK6xlNz13xZsszO3UC7WvY9mGwA8zJk3cXDgLG59WeT3blVW3di15Lr9V/gDL7oEtyHbCzVxql9/wYuyl3r/mR3kVUBe5P9/fQrqWMwS+gm9eSpLU8t3gBPrWdi8YCnF9mH/Mi0XEX2wT43fQCdmd+HkoAnlV2bPsy2KSn/BtmH/btkQdW/yX0Al2w7MrVjXpomAqfn1u9MluGZR3ZnywUsHvAcndqxa0n56unDbwZZcDYqdz43kgUN88i+QR9YS9t6ko1n2bSWdQ8Af0zzB5EFXB+m9u+dymtuX56Z6r8zt//PyMbJTM61v76A51CyQPJDsi7Jv/DlALQv8HT695tM+qBO6zqm8iG5sjXTua+ZlpWu7aRUxyvAMbntj+WLO4Bqputz6+eRGw9T0vbPzy0tLw/8PbVpJnBGLftMAI6v43g1QfGKtazrThaUzE/ncmRu3XmpLfPyU279LWS/r/NS/afl1n0r7bugZP++af0PyMYbzU+/b7eSxrjlrsEnJfueU8/fxAklZWekazWX7Fb65VP5KmTB45y07kXg/0r2bZ/W1zk2zpOntj7VDIgzK2uSdiYLYNaOiOqWbk9rJOkN4PsR8a+WbouZ2dLmMTxW9iQtS/YwxWsc7NRO2VOKgyzTZmZWdtoteROztkvSRmS38z4PHNfCzWmVlL0GYmOy7ikHhGZWltylZWZmZmXPXVpmZmZW9hzwmJmZWdlrtWN4PnvvTfe1mbWADqv3XfJGZlaIhZ9OretBroVoymftsiuv26xtXFpabcBjZmZmBate1NItaDYOeMzMzCpVBd2Y6YDHzMysUlU74DEzM7MyV0mP3nLAY2ZmVqmc4TEzM7Oy5wyPmZmZlT3fpWVmZmZlr4IyPH7SspmZmZU9Z3jMzMwqVQUNWnaGx8zMrEJFVDd6WhJJf5f0jqSXcmXdJT0s6fX0s1tu3dmSJkp6VdLeufKtJL2Y1l0uSal8eUn/SOVPS1q7IefqgMfMzKxSVVc3flqy64F9SsrOAh6JiPWBR9IykjYG+gO90z5XSqpK+1wFDALWT1PNMY8HZkfEesClwO8a0igHPGZmZpUqqhs/LemQEY8Ds0qK+wFD0vwQ4MBc+a0R8UlEvAVMBLaV1APoHBFPRUQAQ0v2qTnW7cDuNdmf+ngMj5mZWaVqvtvSV4uI6QARMV3Sqqm8JzAqt92UVPZZmi8tr9lncjrWQkkfACsB79XXAGd4zMzMKlUTMjySBkl6JjcN+gotqC0zE/WU17dPvZzhMTMzq1RNuEsrIgYDgxu520xJPVJ2pwfwTiqfAvTKbbcGMC2Vr1FLeX6fKZLaAV1YvAttMc7wmJmZVaoCxvDU4R5gYJofCAzPlfdPd16tQzY4eXTq/vpQUp80PmdAyT41xzoU+Hca51MvZ3jMzMwqVQHP4ZF0C7ALsLKkKcB5wEXAMEnHA5OAwwAiYrykYcDLwELglIioGVh0EtkdXx2AEWkCuBa4QdJEssxO/wa1qwFBUYv47L03W2fDzMpch9X7tnQTzCrWwk+nLvFuo6Xp4+cfaPRnbfvN92vWNi4tzvCYmZlVqgp6l5YDHjMzs0pVQa+WcMBjZmZWqZzhMTMzs7LXfA8ebHEOeMzMzCqVMzxmZmZW9ipoDI8fPGhmZmZlzxkeMzOzSuUuLTMzMyt7FdSl5YDHzMysUjngMTMzs3L3xWuryp8DHjMzs0rlDI+ZmZmVPQ9aNjMzs7LnDI+ZmZmVPWd4zMzMrOw5w2NmZmZlzxkeMzMzK3vO8JiZmVnZc8BjZmZmZc9dWmZmZlb2nOExMzOzsucMj5mZmZW9CsrwLNPSDTAzMzMrmjM8ZmZmlcpdWmZmZlb2KqhLywGPmZlZpXLAY2ZmZmUvoqVb0Gwc8JiZmVUqZ3jMzMys7DngMTMzs7Lnu7TMzMys7DnDY2ZmZmWvggYtF/qkZUkXlCxXSbqpyDrNzMysgaqrGz+1UUW/WmJNSWcDSFoeuAt4veA6zczMrCEqKOApukvrOOCmFPTsCoyIiEsLrtPMzMwawoOWvxpJW+YWLwP+CvwHeEzSlhExtoh6zczMrOGiunLG8BSV4bm4ZHk2sHEqD2C3guo1MzOzhmrDXVSNVUjAExG7FnFcMzMzW4rcpfXVSdoQ6Af0JMvqTAOGR8SEouo0MzOzRqigLq1C7tKS9P+AWwEBo4Exaf5WSWcVUaeZmZlZXYrK8BwP9I6Iz/KFki4BxgMXFVSvmZmZNZTH8Hxl1cDqwP9KynukdWZmZtbSHPB8ZT8CHpH0OjA5la0JrAecWlCdtpSd+5tLePw/o+nerSt333g1AB/M/ZAf//y3TJsxk9W/thoX/+psunRekanTZ/KdIwex9pprALBZ7w0578wffOl4p555PlOmzfj8WHff/zAXX3kNq668MgBHHHIAh35nn2Y8Q7O254en/R/f+94RRAQvvTSB4084g/3335Nf/PwMNtpwfbbf4ds8O/YFANZaaw1eemEkr772JgBPPz2WU071qALLqaBXSxR1l9aDkjYAtiUbtCxgCjAmIhYVUactfQfutydHHvIdzvnVHz8vu+aGYfTZegtOOOZwrrlhGNfeOIwzTj4egF49e3DHkCtqPdbDI/9Dx44dFivfZ7dv8bMfn1zMCZiVmdVX/xqnnvI9Nt18Vz7++GNuuflqvnt4P0aPGcthh/8fV12x+GiBN978H1tvs1cLtNbahArK8BT2aomIqI6IURFxR0TcDrzmYKdt2XqLTenSecUvlT36xFP023cPAPrtuwf/fvypJR5nwYKPGPqPO/n+wP6FtNOskrRr144OHdpTVVVFxw4dmD59BhMmTOS1195o6aZZW1QdjZ/aqKLu0jo3N7+xpNeAZyW9LWm7Iuq05vH+7DmssnJ3AFZZuTuz5nzw+bqp02dw6LGncOwpP+XZcS99Xv7nvw1lYP+Dad++/WLHe/ixJzlowEmc/rNfM33mu8WfgFkbNm3aDC659GreemM0UyY9xwdz5/Lwvx6vd5911l6TMaP/yb//dTs77bhtM7XU2oyobvzURhWV4Tk4N/8H4IcRsQ5wOOB3aZWhVVbqxsN3DuX266/gpz8YxJm//B3z5s9nwmtvMGnqNPb41o6L7bPLTtvx0O3Xc9fQq+iz9Tf52a9LH9BtZnldu3bhOwfszXob9KHXWlvSqVNHjjzy4Dq3nz79Hdb5+rZss+3e/OSnv+SGoVew4oorNGOLrdUrKMMj6XRJ4yW9JOkWSe0ldZf0sKTX089uue3PljRR0quS9s6VbyXpxbTucklq6qkW/bZ0gNUjYgRARIwGFh/IkUgaJOkZSc9cM/SWZmiaNdZK3bry7nuzAHj3vVl079oFgOWWW46uXToD0HvD9enVswdvT5rKuPGv8PKEiex1yEAGnPRj3p48lWNPPROArl06s9xyywFw6Hf24eVXX2+BMzJrO3bfvS9vvT2J996bxcKFC7nr7hFs32frOrf/9NNPmTVrNgBjn3uRN998mw3WX7e5mmttQFRXN3paEkk9gdOArSNiE6AK6A+cBTwSEesDj6RlJG2c1vcG9gGulFSVDncVMAhYP01NvrOlqIBnXUn3SLoXWENSx9y6ZevaKSIGR8TWEbH1CQOOKKhp9lXsslMfho/4FwDDR/yLXftuD8Cs2XNYtCgbojV56nQmTZ5Gr5496H/Q/jx6z008dMcQhl51MWv36sn1f/k9wOeBE8CjT45i3bV6NfPZmLUtkydNZbvttqRDh6x7eLddd2LChLq/KKy8cneWWSb73/w666zJeuutw5tvTWqWtlobUdwYnnZAB0ntgI5kb1voBwxJ64cAB6b5fsCtEfFJRLwFTAS2ldQD6BwRT0VEAENz+zRaUbel9ytZXgZA0mpk0Zq1AT897yLGPPcCc+bMZfcDj+bk44/hhGMO58c//w133vdPeqy2Cpf8+mcAPDvuJf5yzQ1Utauiapll+MVPT11swHOpG28bzsgnR1HVroouK67Ir8/9cXOcllmbNXrMc9x55/2MGf1PFi5cyLhx4/nbNTfRr98+XHbpr1llle7cM3wozz8/nv32P4q+fftw/nk/YeHCRSxatIhTTj2b2bPntPRpWGtSwJiciJgq6Y/AJOAj4KGIeEjSahExPW0zXdKqaZeewKjcIaakss/SfGl5kyha6T34n733ZutsmFmZ67B635ZuglnFWvjp1CaPUWmK+Rcc1ejP2hXOu/n7ZN1MNQZHxOCahTQ25w7gu8Ac4DbgduAvEdE1t93siOgm6QrgqYi4MZVfCzxAFjD9NiL2SOV9gTMj4oDGthmaYQyPpDPzP83MzKyVqK5u9JQffpKmwSVH3QN4KyLeTa+YuhPYAZiZuqlIP99J208B8mMa1iDrApuS5kvLm6Q5Bi33L/lpZmZmrUExY3gmAX0kdUx3Ve0OvALcAwxM2wwEhqf5e4D+kpaXtA7Z4OTRqfvrQ0l90nEG5PZptKLG8NSmWdN0ZmZmtgTFjOF5WtLtwFhgIfAcMBhYARgm6XiyoOiwtP14ScOAl9P2p+QeVHwScD3ZHd4j0tQkzRnwmJmZWWtS0JOTI+I84LyS4k/Isj21bX8hcGEt5c8AmyyNNjngMTMzq1ANea5OuWiOMTxmZmZmLao5Mjwj089Hm6EuMzMza6g2/DLQxio84ImIM/I/zczMrJWooICnsC6tdDva5iVla6Z3bJiZmVlL89vSl4rPgDsldcqVXQP0KLBOMzMza6ji3qXV6hQW8KSnK95F9mhpJK0JrJJuMTMzM7MWFtXR6KmtKvourWuA49L8AOC6guszMzOzhqqgDE+hg5YjYoIkJG0AHAHsVGR9ZmZm1ggV9Bye5rgt/VqyTM8LETG7GeozMzOzhmjDGZvGao4HDw4DNicLfMzMzKy1cJfW0hMRC4AuRddjZmZmjRPRdgOYxvK7tMzMzCpVG87YNJYDHjMzs0rlgMfMzMzKXVt+rk5jOeAxMzOrVA54zMzMrOxVzmN4HPCYmZlVKndpmZmZWfmroICnOR48aGZmZtainOExMzOrVB7DY2ZmZuXOY3jMzMys/DnDY2ZmZuXOGR4zMzMrf87wmJmZWbkLBzxmZmZW9hzwmJmZWblzhsfMzMzKnwMeMzMzK3fO8JiZmVnZc8BjZmZmZc8Bj5mZmZW/UEu3oNk44DEzM6tQzvCYmZlZ2YtqZ3jMzMyszFVShmeZlm6AmZmZWdHqzPBI+jNQ52tUI+K0QlpkZmZmzSI8aBmAZ5qtFWZmZtbsKqlLq86AJyKG5JcldYqI+cU3yczMzJpDJQ1aXuIYHknbS3oZeCUtby7pysJbZmZmZoWKaPzUVjVk0PKfgL2B9wEi4nlg5wLbZGZmZs0gqtXoqa1q0G3pETFZ+tJJLiqmOWZmZtZc2nIA01gNCXgmS9oBCEnLAaeRurfMzMys7WrLXVSN1ZCA50TgMqAnMBX4J3BKkY0yMzOz4jnDkxMR7wFHNUNbzMzMrBlV0nN4GnKX1rqS7pX0rqR3JA2XtG5zNM7MzMyKE9WNn9qqhtyldTMwDOgBrA7cBtxSZKPMzMyseNWhRk8NIamrpNslTZD0SnrETXdJD0t6Pf3sltv+bEkTJb0qae9c+VaSXkzrLlfJHVSN0ZCARxFxQ0QsTNON1PPKCTMzM2sbItToqYEuAx6MiA2BzcludjoLeCQi1gceSctI2hjoD/QG9gGulFSVjnMVMAhYP037NPVc6wx4UiTWHXhU0lmS1pa0lqQzgfubWqGZmZm1DkU8h0dSZ7Ln9V0LEBGfRsQcoB9Q8xaHIcCBab4fcGtEfBIRbwETgW0l9QA6R8RTERHA0Nw+jVbfoOVnyTI5NWf3/dy6AH7V1ErNzMys5RV0W/q6wLvAdZI2J4snfgisFhHTs3pjuqRV0/Y9gVG5/aekss/SfGl5k9T3Lq11mnpQMzMza/2aclu6pEFk3Uw1BkfE4NxyO2BL4AcR8bSky0jdV3Udsram1VPeJA160rKkTYCNgfaf1xgxtKmVmpmZWctr6CDkvBTcDK5nkynAlIh4Oi3fThbwzJTUI2V3egDv5Lbvldt/DWBaKl+jlvImacht6ecBf07TrsDvge80tUIzMzMrXxExg+wtDd9IRbsDLwP3AANT2UBgeJq/B+gvaXlJ65ANTh6dur8+lNQn3Z01ILdPozUkw3Mo2Qjr5yLiOEmrAdc0tUIzMzNrHQp88OAPgJvSK6neBI4jS7IMk3Q8MAk4LGtDjJc0jCwoWgicEhE17+w8Cbge6ACMSFOTNCTg+SgiqiUtTCOv3yEbkGRmZmZtWFHv0oqIccDWtazavY7tLwQurKX8GWCTpdGmhgQ8z0jqCvyNbKT1PGD00qjczMzMWk5TxvC0VQ15l9bJafZqSQ+S3RP/QrHNMjMzs6JV0ru06gx4JG1Z37qIGFtMk8zMzKw5FNWl1RrVl+G5uJ51Aey2lNtiZmZmzchdWkBE7NqcDSm11SZHtWT1ZhVrrc6rtXQTzKyZuEvLzMzMyp4zPGZmZlb2KmgIjwMeMzOzSlVJGZ6GvFpCko6W9Iu0vKakbYtvmpmZmRUpQo2e2qolBjzAlcD2wBFp+UPgisJaZGZmZs2iuglTW9WQLq3tImJLSc8BRMTs9G4MMzMza8OCtpuxaayGBDyfSaoijW2StAptO8gzMzMzoLqCRi03JOC5HLgLWFXShWRvTz+30FaZmZlZ4aqd4flCRNwk6VmyN5wKODAiXim8ZWZmZlYod2nlSFoTWADcmy+LiElFNszMzMxsaWlIl9b9ZON3BLQH1gFeBXoX2C4zMzMrWCUNyG1Il9am+eX0FvXvF9YiMzMzaxbu0qpHRIyVtE0RjTEzM7Pm4wxPjqQzcovLAFsC7xbWIjMzM2sWDni+bMXc/EKyMT13FNMcMzMzay7u0krSAwdXiIifNlN7zMzMrJlUV068U3fAI6ldRCxMg5TNzMyszPjBg5nRZON1xkm6B7gNmF+zMiLuLLhtZmZmVqAKerNEg8bwdAfeB3bji+fxBOCAx8zMrA3zoOXMqukOrZf4ItCpUUlBoZmZWVmqlru0AKqAFaDWDj4HPGZmZm1cJX2Y1xfwTI+IC5qtJWZmZtas3KWVqZw8l5mZWQXybemZ3ZutFWZmZtbsfFs6EBGzmrMhZmZm1rw8hsfMzMzKXiV1aS3T0g0wMzMzK5ozPGZmZhXKd2mZmZlZ2fMYHjMzMyt7lTSGxwGPmZlZhXKXlpmZmZU9BzxmZmZW9sJdWmZmZlbunOExMzOzsueAx8zMzMqeb0s3MzOzsufb0s3MzKzsuUvLzMzMyp4DHjMzMyt7HsNjZmZmZc9jeMzMzKzsVVKX1jIt3QAzMzNrGdGEqaEkVUl6TtJ9abm7pIclvZ5+dstte7akiZJelbR3rnwrSS+mdZdLanJOygGPmZlZhaomGj01wg+BV3LLZwGPRMT6wCNpGUkbA/2B3sA+wJWSqtI+VwGDgPXTtE9Tz9UBj5mZmS1VktYAvg1ckyvuBwxJ80OAA3Plt0bEJxHxFjAR2FZSD6BzRDwVEQEMze3TaB7DY2ZmVqEKHMPzJ+BMYMVc2WoRMR0gIqZLWjWV9wRG5babkso+S/Ol5U3iDI+ZmVmFasoYHkmDJD2Tmwbljylpf+CdiHi2gc2obVxO1FPeJM7wmJmZVaimZHgiYjAwuJ5NdgS+I2k/oD3QWdKNwExJPVJ2pwfwTtp+CtArt/8awLRUvkYt5U3iDI+ZmVmFqlbjpyWJiLMjYo2IWJtsMPK/I+Jo4B5gYNpsIDA8zd8D9Je0vKR1yAYnj07dXx9K6pPuzhqQ26fRnOExMzOrUI286+qruggYJul4YBJwGEBEjJc0DHgZWAicEhGL0j4nAdcDHYARaWoSBzxmZmYVquhwJyJGAiPT/PvA7nVsdyFwYS3lzwCbLI22OOAxMzOrUJX0pGUHPGZmZhWqmbu0WpQDHjMzswpVOeGOAx4zM7OKVUldWoXeli5pq1rKDiiyTjMzM2uYgt+l1aoU/Ryev0natGZB0hHAuQXXaWZmZg1Q5NvSW5uiu7QOBW6XdBSwE9lDg/YquE4zMzNrgErq0io04ImINyX1B+4GJgN7RcRHRdZpZmZmDRNtOmfTOIUEPJJe5MuZr+5AFfC0JCJisyLqNTMzs4Zzhuer27+g45qZmdlS0pYHITdWIQFPRPwPQNJqQE+ybM+0iJhZRH1mZmZm9SmqS2sL4GqgCzA1Fa8haQ5wckSMLaJeK84vL/0Z39pzB2a9N5uDdzkagA02Xo+f//5MOnbqyLTJ0znr5POYP28B7dpVcf4l57DRpt+gqqqKe28bwbV/HgrAtXdewSqrrsTHH38CwIn9f8Ss92a32HmZtXYXXXYeu+3Vl/ffm8W+fQ8H4PJrLmKdr68FQOcuKzL3gw85YNcj6NqtC1dc93s23aI3d9x6L78863efH+em4YNZdbWV+fij7G/v2MNO5n3/7VW8ysnvFNeldT3w/Yh4Ol8oqQ9wHbB5QfVaQe75x/3c+vfbuPDPv/i87PxLzubiX/6FZ596jgOP2J9jTz6aK34/mL0O2J1ll1uWQ3Y9mvYdlueux29hxN0PMW3yDADOOuV8Xn5+Qkudilmbcset93LDtf/gj1dc8HnZaSec9fn82Reczodz5wHwySefcMlvr2KDjb7OBhuut9ixzjjxZ7w47pXiG21tRiV1aRX1HJ5OpcEOQESMAjoVVKcV6NlR4/hgztwvla399bV49qnnAHjqsdHssf8uAEQEHTt2oKqqiuXbL89nn37GvA8XNHeTzcrCmKfGMmf2B3Wu/3a/PbnvzgcB+GjBxzz79Dg+/fjT5mqetXHVTZjaqqICnhGS7pf0XUk7pOm7ku4HHiyoTmtmEye8yS579wVgrwN242urrwrAw/f9mwULPuKRF+7loWfvZshVNzM3Fyz96k/nMuxfQxh0+nEt0m6zcrHN9lvy3ruzePvNyQ3a/neXn8+9j97CqT8+odiGWZsRTfivrSpq0PJpkvYF+pENWhYwBbgiIh4ook5rfr84/ULO+vXpnHjG9xj50BN89ulCADb5Zm+qF1Wzx+YH0LlrZ66/+ypGPT6GqZOmcfbJ5/POjHfp2Kkjl1z7Gw44bF/uvW1EC5+JWdt0wMF7c++dDfsOecb3f8bMGe/SaYWOXHHdHzjo8G9z17D7C26htXZtOWPTWIU9eDAiRgCN+iSTNAgYBNBzxXXo3nG1IppmS8nbE//Hif1/BMBa6/ai7x47ArDfwXvxn0dHsXDhIma9N5vnxrxI7y02Yuqkabwz410AFsxfwAN3PcQm39zYAY9ZE1RVVbH3t3ej3+5HNWj7melvb/68Bdx7x4NstuUmDnisTWdsGquQLi1Jm+Xml5V0rqR7JP1GUse69ouIwRGxdURs7WCn9eu+cjcAJDHo9OO4behdAEyfOoNtd8reG9uhY3s226o3b73+NlVVVXTt3gWAdu2q+NaeOzJxwpst03izNm7Hb23HGxPfZsb0d5a4bVVVFd26dwWgXbt27LpXX16bMLHgFlpbUEljeIq8S2vLNH8RsBJwMXAg2e3qAwqq1wryu6t+ydY7bEnX7l15eOxwrvzDNXTs1IHvHncIAI88MJK7b7kPgFv/fge/uuxc7nzsJiQx/Nb7ef2VN+jQsT1X3/In2i3bjmWqluHpx8dwx43DW/K0zFq9Pw3+DdvtuBXdunflyRdGcNnvrua2m4az/0F71dqd9djY+1hhxU4su+yy7LnfLhx76MlMnTKd62+7gnbtsr+9/z72NP9IX1CsslVH5WR4FAWcrKTnIuKbaX4csE1EfCZJwPMNebXEZl/bvnL+FcxakfkLP2npJphVrDfeG6vmrO/otQ5u9Gftjf+7s1nbuLQUleHpIukgsi6z5SPiM4CICEkOZMzMzFqBSnoOT1EBz2PAd9L8KEmrRcRMSV8D3iuoTjMzM2uEShq0XNRt6bU+YCUiZgC7F1GnmZmZNU5bHoTcWEU9ePBLJG0tabnmqMvMzMwapppo9NRWFR7wSOoB/Bc4vOi6zMzMrOEq6UnLzZHhGQgMAfwsczMzs1akkp7D0xwBzzHA2cBykr7eDPWZmZlZA0REo6e2qtCAR9KuwISIeA+4Dji+yPrMzMzMalN0hud44No0/w/gMEnNMlDazMzM6udBy0uBpK5AH9ILRCNiLjAK2K+oOs3MzKzhKmkMT5FvS58DrFdSdkxR9ZmZmVnjtOW7rhqrsIDHzMzMWre23EXVWA54zMzMKlRbvuuqsRzwmJmZVai2PCansRzwmJmZVSiP4TEzM7Oy5zE8ZmZmVvY8hsfMzMzKnjM8ZmZmVvY8hsfMzMzKXrW7tMzMzKzcVU6444DHzMysYnkMj5mZmZU9BzxmZmZW9irptvRlWroBZmZmZkVzhsfMzKxCuUvLzMzMyl4lPYfHXVpmZmYVKiIaPS2JpF6SHpX0iqTxkn6YyrtLeljS6+lnt9w+Z0uaKOlVSXvnyreS9GJad7kkNfVcHfCYmZlVqGqi0VMDLAR+HBEbAX2AUyRtDJwFPBIR6wOPpGXSuv5Ab2Af4EpJVelYVwGDgPXTtE9Tz9UBj5mZWYUqIsMTEdMjYmya/xB4BegJ9AOGpM2GAAem+X7ArRHxSUS8BUwEtpXUA+gcEU9FVvHQ3D6N5jE8ZmZmFaroQcuS1ga+CTwNrBYR0yELiiStmjbrCYzK7TYllX2W5kvLm8QZHjMzswoVTfhP0iBJz+SmQbUdW9IKwB3AjyJibj3NqG1cTtRT3iTO8JiZmVWoprw8NCIGA4Pr20bSsmTBzk0RcWcqnimpR8ru9ADeSeVTgF653dcApqXyNWopbxJneMzMzCpUUzI8S5LupLoWeCUiLsmtugcYmOYHAsNz5f0lLS9pHbLByaNT99eHkvqkYw7I7dNozvCYmZlVqKZkeBpgR+AY4EVJ41LZOcBFwDBJxwOTgMMAImK8pGHAy2R3eJ0SEYvSficB1wMdgBFpahIHPGZmZhWqiAcPRsST1D7+BmD3Ova5ELiwlvJngE2WRrsc8JiZmVWogjI8rZIDHjMzswpVSa+WcMBjZmZWoZzhMTMzs7LnDI+ZmZmVvYjqlm5Cs/FzeMzMzKzsOcNjZmZWoYp+l1Zr4oDHzMysQjXk7eflwgGPmZlZhXKGx8zMzMqeMzxmZmZW9vwcHjMzMyt7fg6PmZmZlT13aZmZmVnZ86BlMzMzK3vO8JiZmVnZ86BlMzMzK3vO8JiZmVnZ8xgeMzMzK3vO8JiZmVnZ8xgeMzMzK3t+8KCZmZmVPWd4zMzMrOxV0hieZVq6AWZmZmZFc4bHzMysQnkMj5mZmZW9SurScsBjZmZWoRzwmJmZWdmrnHAHVEnRnTUfSYMiYnBLt8Os0vhvz6x2vkvLijKopRtgVqH8t2dWCwc8ZmZmVvYc8JiZmVnZc8BjRfEYArOW4b89s1p40LKZmZmVPWd4zMzMrOw54LGlTtIukj6QNC5Nv8it20fSq5ImSjorVz5S0tYt02KztkvS9ZLeyv29bZHKJeny9Lf2gqQtU/nakl5q0UabtQA/eNAaRNJywLIRMb+BuzwREfuXHKMKuALYE5gCjJF0T0S8vHRba1Y+JHWLiNlL2OynEXF7Sdm+wPpp2g64Kv00q0jO8Fi9JG0k6WLgVWCDr3i4bYGJEfFmRHwK3Ar0K6lvGUlDJP36K9ZlVi6ekXSzpN0kqRH79QOGRmYU0FVSj/wGktaV9JykbZZqi81aIQc8thhJnSQdJ+lJ4BrgFWCziHgurb80lz7PT2flDrO9pOcljZDUO5X1BCbntpmSymq0A24CXouIcws7QbO2ZQPgZuBU4GVJ50havWSbC1O31aWSlk9l9f69SfoGcAdwXESMKa75Zq2Du7SsNtOBF4ATImJC6cqIOH0J+48F1oqIeZL2A+4mS6vX9u00f5vgX4FhEXFhk1ptVoYiYhFwH3CfpFWA3wKTJO0QEaOBs4EZwHJkt6T/P+AC6v97WwUYDhwSEeMLPgWzVsEZHqvNocBU4C5Jv5C0Vn7lkjI8ETE3Iual+QeAZSWtTPYNs1fuUGsA03LL/wV2ldS+wHMza3MkdZE0CLiHLONzPNmXEiJieuq2+gS4jqzrGOr/e/uALPuzYzM036xVcIbHFhMRDwEPSVoJOBoYLuk9sozP20vK8Ej6GjAzIkLStmSB9fvAHGB9SeuQBVT9gSNzu14L7AzcJumgiFi4tM/NrK2RdCOwPXAbMCAiXi9Z3yMipqfxPQcCNXdg3QOcKulWssHKH6Tt1gY+Tdv+U9K8iLi5WU7GrAU54LE6RcT7wGXAZSlwWdTAXQ8FTpK0EPgI6B/ZEy4XSjoV+CdQBfy9NJ0eEZdI6gLcIOmoiKheWudj1kYNA46t5wvATamrS8A44MRU/gCwHzARWAAcl98pIuZL2h94WNL8iBheROPNWgs/adnMzMzKnsfwmJmZWdlzwGNmZmZlzwGPmZmZlT0HPGZmZlb2HPCYmZlZ2XPAY9bCJC1KD258SdJtkjp+hWNdL+nQNH+NpI3r2XYXSTs0oY6304MkG1Ress28RtZ1vqSfNLaNZmalHPCYtbyPImKLiNiE7IFwJ+ZXprfMN1pEnLCEN9HvAjQ64DEza4sc8Ji1Lk8A66Xsy6OSbgZelFQl6Q+SxqSXRH4fQJm/SHpZ0v3AqjUHkjRS0tZpfh9JY9MLXR9JT9s9ETg9ZZf6SlpF0h2pjjGSdkz7riTpofRW7b9S+zuavkTS3ZKelTQ+vRIhv+7i1JZH0gPzkPR1SQ+mfZ6QtOFSuZpmZomftGzWSkhqB+wLPJiKtgU2iYi3UtDwQURsk96G/R9JDwHfBL4BbAqsBrwM/L3kuKsAfwN2TsfqHhGzJF0NzIuIP6btbgYujYgnJa1J9kTsjYDzgCcj4gJJ3wa+FMDU4Xupjg7AGEl3pCd3dwLGRsSPJf0iHftUspdenhgRr0vaDrgS2K0Jl9HMrFYOeMxaXgdJ49L8E2TvFNsBGB0Rb6XyvYDNasbnAF3I3kC/M3BLeqP2NEn/ruX4fYDHa44VEbPqaMcewMbZK5kA6CxpxVTHwWnf+yXNbsA5nSbpoDTfK7X1faAa+EcqvxG4U9IK6Xxvy9W9fAPqMDNrMAc8Zi3vo4jYIl+QPvjn54uAH0TEP0u22w9Y0vth1IBtIOvi3j4iPqqlLQ1+B42kXciCp+0jYoGkkUD7OjaPVO+c0mtgZrY0eQyPWdvwT7IXsi4LIGkDSZ2Ax4H+aYxPD2DXWvZ9CvhWeks9krqn8g+BFXPbPUTWvUTabos0+zhwVCrbF+i2hLZ2AWanYGdDsgxTjWXIXi4LcCRZV9lc4C1Jh6U6JGnzJdRhZtYoDnjM2oZryMbnjJX0EvBXsgztXcDrwIvAVcBjpTtGxLtk427ulPQ8X3Qp3QscVDNoGTgN2DoNin6ZL+4W+yWws6SxZF1rk5bQ1geBdpJeAH4FjMqtmw/0lvQs2RidC1L5UcDxqX3jgX4NuCZmZg3mt6WbmZlZ2XOGx8zMzMqeAx4zMzMrew54zMzMrOw54DEzM7Oy54DHzMzMyp4DHjMzMyt7DnjMzMys7DngMTMzs7L3/wFtKEel2r7uhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "# Instantiate the classifier\n",
    "gnb = GaussianNB()\n",
    "#bnb = BernoulliNB()\n",
    "#mnb = MultinomialNB()\n",
    "\n",
    "# Train classifier\n",
    "gnb.fit(x_train,y_train)\n",
    "#bnb.fit(x_train,y_train)\n",
    "#mnb.fit(x_train,y_train)\n",
    "\n",
    "# Test the classifier\n",
    "predict = gnb.predict(x_test)\n",
    "#predict = bnb.predict(x_test)\n",
    "#predict = mnb.predict(x_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "      .format(x_test.shape[0], (y_test != predict).sum(), \n",
    "              gnb.score(x_test,y_test)*100 ))\n",
    "\n",
    "# Creates a confusion matrix\n",
    "cm = confusion_matrix(y_test, predict)\n",
    "\n",
    "# Transform to dataframe for easier plotting\n",
    "cm_df = pd.DataFrame(cm, index = ['<=50k','>50k'], \n",
    "                     columns = ['<=50k','>50k'])\n",
    "# plot the confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(cm_df, annot=True, fmt='g')\n",
    "plt.title(\"Naive Bayes Accuracy:\" + str(gnb.score(x_test,y_test)*100))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Summary\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "-  Computationally **fast**\n",
    "-  Simple to implement\n",
    "-  Works well with **small datasets**\n",
    "-  Works well with **high dimensions**\n",
    "-  Perform well even if the Naive assumption is **not perfectly met**. In many cases, the approximation is enough to build a good classifier.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "-  Require to **remove correlated features** because they are voted twice in the model and it can lead to over inflating importance (overfitting problem).\n",
    "- If a **categorical variable** has a category in *testing* data set which was **not observed** in *training* data set, then the model will assign a **zero probability** and **failed** to make a *prediction*. This is often known as **\"Zero Frequency\"**. To solve this, we can use the **smoothing technique**. One of the simplest smoothing techniques is called **Laplace estimation**. `sklearn` applies **Laplace smoothing** by default when you train a Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "05.05-Naive-Bayes.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
